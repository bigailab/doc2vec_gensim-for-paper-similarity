{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AlexAiken_3.txt', 'StratosIdreos_1.txt', 'StratosIdreos_3.txt', 'GeoffreyFox_3.txt', 'AlexAiken_2.txt', 'GeoffreyFox_2.txt', 'GeoffreyFox_1.txt', 'DanBoneh_3.txt', 'DanBoneh_1.txt', 'AlexAiken_1.txt', 'StratosIdreos_2.txt', 'DanBoneh_2.txt']\n",
      "model is saved\n"
     ]
    }
   ],
   "source": [
    "import gensim.models as gsm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import OrderedDict\n",
    "\n",
    "#path to the input corpus files\n",
    "train_corpus=\"/home/betul/papers\"\n",
    "\n",
    "#tagging the text files\n",
    "class DocIterator(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield TaggedDocument(words=doc.split(), tags=[self.labels_list[idx]])\n",
    "\n",
    "docLabels = [f for f in listdir(train_corpus) if f.endswith('.txt')]\n",
    "print(docLabels)\n",
    "data = []\n",
    "for doc in docLabels:\n",
    "    data.append(open(join(train_corpus, doc), 'r').read())\n",
    "    \n",
    "it = DocIterator(data, docLabels)\n",
    "\n",
    "#train doc2vec model\n",
    "model = gsm.Doc2Vec(size=300, window=10, min_count=1, workers=11,alpha=0.025, min_alpha=0.025) # use fixed learning rate\n",
    "model.build_vocab(it)\n",
    "model.train(it, total_examples=len(doc), epochs=20)\n",
    "\n",
    "\n",
    "model.save(\"paper.model\")\n",
    "\n",
    "print(\"model is saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is loaded\n"
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "model=\"paper.model\"\n",
    "m=gsm.Doc2Vec.load(model)\n",
    "print(\"model is loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DanBoneh_2.txt', 0.9468926191329956),\n",
       " ('DanBoneh_1.txt', 0.923835813999176),\n",
       " ('DanBoneh_3.txt', 0.7840186953544617)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path to test files\n",
    "test_paper=\"/home/betul/test_paper/DanBoneh_4.txt\"\n",
    "new_test = open(join(test_paper), 'r').read().split()\n",
    "#print(new_test)\n",
    "inferred_docvec = m.infer_vector(new_test)\n",
    "m.docvecs.most_similar([inferred_docvec], topn=3)\n",
    "#print('%s:\\n %s' % (model, m.docvecs.most_similar(positive=[inferred_docvec], topn=5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
